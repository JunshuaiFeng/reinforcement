{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_mountain_car_policy#\n",
    "Task: Implement an explicit policy for the mountain car environment without using any learning algorithm. Explain in detail your reasoning behind your policy and run several test episodes to measure its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 154 timesteps.\n",
      "Episode 1 finished after 156 timesteps.\n",
      "Episode 2 finished after 165 timesteps.\n",
      "Episode 3 finished after 99 timesteps.\n",
      "Episode 4 finished after 164 timesteps.\n",
      "Episode 5 finished after 163 timesteps.\n",
      "Episode 6 finished after 174 timesteps.\n",
      "Episode 7 finished after 153 timesteps.\n",
      "Episode 8 finished after 119 timesteps.\n",
      "Episode 9 finished after 164 timesteps.\n",
      "\n",
      "Success Rate: 100%\n"
     ]
    }
   ],
   "source": [
    "totalReward = 0\n",
    "numEpisodes = 10\n",
    "\n",
    "for i_episode in range(numEpisodes):\n",
    "    observation = env.reset() # observation = [position, velocity]\n",
    "    for t in range(200):\n",
    "        env.render()\n",
    "        \n",
    "        #if car is on the right, push left, and vise versa\n",
    "        action = 2 if observation[1] > 0 else 0\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            if t+1 < 200: # reach flag before the time limit\n",
    "                totalReward += 1\n",
    "            print(\"Episode {} finished after {} timesteps.\".format(i_episode, t+1))\n",
    "            break\n",
    "    env.close()\n",
    "    \n",
    "print(\"\\nSuccess Rate: {}%\".format(int(totalReward * 100 /numEpisodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
